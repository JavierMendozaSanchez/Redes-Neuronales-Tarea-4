# -*- coding: utf-8 -*-
"""Polinomio de grado 3

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xNBAAvvXmkAc3xgXg0qMmuuZed1G-A9q
"""

#importamos las librerias a utilizar
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
import matplotlib.pyplot as plt
#hacemos la capa personalizada
class Polinomio(layers.Layer):
    def __init__(self):
        super(Polinomio, self).__init__()
        # definimos los coeficientes para ser entrenables usando  un valor
        #aleatorio al inicializarse dado de una distrubicion normal
        #cada coeficiente sera un escalar
        #ademas le decimos a la maquina que estos seran entrenables
        #coeficiente de la constante
        self.a0 = self.add_weight(shape=(1,),
                                  initializer="random_normal",
                                  trainable=True, name="a0")
       #coeficiente de x
        self.a1 = self.add_weight(shape=(1,),
                                  initializer="random_normal",
                                  trainable=True, name="a1")
       #coeficiente de x^2
        self.a2 = self.add_weight(shape=(1,),
                                  initializer="random_normal",
                                  trainable=True, name="a2")
        #coeficiente de x^3
        self.a3 = self.add_weight(shape=(1,),
                                  initializer="random_normal",
                                  trainable=True, name="a3")
#aqui hacemos definimos lo que le pasara a la entrada input al pasar por la capa
#es decir pasara al polinimio de grado 3
    def call(self, inputs):
        x = inputs
        return self.a0 + self.a1*x + self.a2*(x**2) + self.a3*(x**3)

# creamos el modelo que usara la red usando uno secuencial con solo la capa
#del polinomio
model = keras.Sequential([
    keras.Input(shape=(1,)),
    Polinomio()
])

#estos son los parametros del entrenamiento usando solo 200 puntos en el inter
#valo de -1 a 1
x_train = np.linspace(-1, 1, 200).reshape(-1,1)
#y queremos llegar a esta funcion
y_train = np.cos(2*x_train)

#se compila usando adam con un learning rate de 0.001 y ademas se entrena con
#distintas epocas
#inicialmente use 500 epocas y de ahi pase a 1000
model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01), loss="mse")
history = model.fit(x_train, y_train, epochs=1000, verbose=0)

#Generamos la grafica de la perdida
plt.plot(history.history['loss'])
plt.xlabel("Época")
plt.ylabel("Loss (MSE)")
plt.title("Entrenamiento del polinomio")
plt.show()

# necesitamos valores de comparacion o lo que se le dice tambien como una
#prediccion de la funcion "real"
#le damos las mismas caracteristicas solo que estan seran el tes y la prediccion
x_test = np.linspace(-1, 1, 200).reshape(-1,1)
y_pred = model.predict(x_test)

#generamos la graficas para que las muestre
#esta es para la funcion "real"
plt.plot(x_test, np.cos(2*x_test), label="cos(2x)")
plt.plot(x_test, y_pred, '--', label="Polinomio cúbico entrenado")
plt.legend()
plt.xlabel("x")
plt.ylabel("y")
plt.title("Aproximación de cos(2x) con un polinomio de grado 3")
plt.grid(True)
plt.show()

# 8hacemos que nos de el valor de los coeficientes aprendidos
a0 = model.layers[0].a0.numpy()[0]
a1 = model.layers[0].a1.numpy()[0]
a2 = model.layers[0].a2.numpy()[0]
a3 = model.layers[0].a3.numpy()[0]
print(f"Coeficientes entrenados:\na0 = {a0:.4f}, a1 = {a1:.4f}, a2 = {a2:.4f}, a3 = {a3:.4f}")