# -*- coding: utf-8 -*-
"""Reproducción de funciones

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xkMr16r6BWSSBd8Gr_O4BCX4fUh2Ufft
"""

#Importamos las librerias, capas y el optimizador
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
import numpy as np
#esto para graficar
import matplotlib.pyplot as plt

#en este caso se definen parametros
#se define x
#se especifica el intervalo -1 a 1 y se usan 200 puntos de ese intervalo
x_train = np.linspace(-1, 1, 200).reshape(-1,1)
#se deine y y aqui es donde va la funcion es decir nuestra y=f(x)
#en este caso tenemos dos ecuaciones dejamos como comentario 1 y la otra la usamos
#y luego intercambiamos
y_train = 1 + 2 * x_train + 4 * x_train**3
#y_train = 3 * np.sin(np.pi * x_train)
# construimos la red secuancial
model = Sequential()
#agregamos una capa densa de 20 neuronas con la funcion de activacion tanh
#esto nos permite tener valores negativos
model.add(Dense(20, activation='tanh', input_shape=(1,)))
#le agregamos otra capa de 20 neuronas
model.add(Dense(20, activation='tanh'))
#la salida sera una neurona
model.add(Dense(1))

# compilamos usando el optimizador  y incluimos el loss
model.compile(optimizer=Adam(learning_rate=0.01), loss='mse')
#iniciamos el entrenamiento de la red con 500 epocas
history = model.fit(x_train, y_train, epochs=500, verbose=0)

# Hacemos la grafica de la perdida loss
plt.plot(history.history['loss'])
plt.xlabel("Época")
plt.ylabel("Loss (MSE)")
plt.title("Evolución del error durante el entrenamiento")
plt.show()

# Debe de haber una prediccion de la curva para ello usamos el test para valores
#de x
x_test = np.linspace(-1, 1, 200).reshape(-1,1)
y_pred = model.predict(x_test)

# Hacemos las 2 graficas!
#tenemos 2 funciones hacemos lo mismo que cuando definimos y dejamos una comentada
plt.plot(x_test,1 + 2 * x_test + 4 * x_test**3, label="1+2x+4x^3 (real)")
#plt.plot(x_test, 3*np.sin(np.pi*x_test), label="Función real  de 3 sin(πx)")
plt.plot(x_test, y_pred, label="Red neuronal", linestyle="--")
plt.legend()
plt.xlabel("x")
plt.ylabel("y")
plt.title("Aproximación de la función")
plt.grid(True)
plt.show()